{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a11d1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from telegram.ext import Updater, MessageHandler, Filters\n",
    "from telegram import Update\n",
    "from telegram.ext import CallbackContext\n",
    "from torchvision import transforms\n",
    "\n",
    "# === –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ ===\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# === –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏ ===\n",
    "class Simple3DCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv3d(3, 32, kernel_size=(3,3,3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d((1,2,2)),\n",
    "\n",
    "            nn.Conv3d(32, 64, kernel_size=(3,3,3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d((2,2,2)),\n",
    "\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 8 * 28 * 28, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # (B, T, C, H, W) -> (B, C, T, H, W)\n",
    "        x = x.permute(0, 2, 1, 3, 4)\n",
    "        return self.model(x)\n",
    "\n",
    "# === –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ ===\n",
    "model = Simple3DCNN()\n",
    "model.load_state_dict(torch.load(\"violence_detector.pth\", map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# === –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ ===\n",
    "frame_size = (112, 112)\n",
    "frames_per_video = 16\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(frame_size),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# === –§—É–Ω–∫—Ü–∏—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–∞–¥—Ä–æ–≤ ===\n",
    "def extract_frames(video_path, num_frames=16):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_indices = torch.linspace(0, total_frames - 1, num_frames).long()\n",
    "    frames = []\n",
    "    for i in range(total_frames):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if i in frame_indices:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame_tensor = transform(frame)\n",
    "            frames.append(frame_tensor)\n",
    "    cap.release()\n",
    "    if len(frames) < num_frames:\n",
    "        for _ in range(num_frames - len(frames)):\n",
    "            frames.append(frames[-1])\n",
    "    return torch.stack(frames)  # (T, C, H, W)\n",
    "\n",
    "# === –§—É–Ω–∫—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è ===\n",
    "def predict_violence(video_path, model, device):\n",
    "    frames_tensor = extract_frames(video_path, frames_per_video)\n",
    "    frames_tensor = frames_tensor.unsqueeze(0).to(device)  # (1, T, C, H, W)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(frames_tensor)\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        pred = torch.argmax(probs, dim=1).item()\n",
    "    return pred\n",
    "\n",
    "# === –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è ===\n",
    "def handle_video(update: Update, context: CallbackContext):\n",
    "    video = update.message.video or update.message.document\n",
    "    if video is None:\n",
    "        update.message.reply_text(\"–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –≤–∏–¥–µ–æ—Ñ–∞–π–ª.\")\n",
    "        return\n",
    "    \n",
    "    file = video.get_file()\n",
    "    file_path = f\"{video.file_unique_id}.mp4\"\n",
    "    file.download(file_path)\n",
    "\n",
    "    update.message.reply_text(\"üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –≤–∏–¥–µ–æ, –ø–æ–¥–æ–∂–¥–∏—Ç–µ...\")\n",
    "\n",
    "    pred = predict_violence(file_path, model, device)\n",
    "    os.remove(file_path)\n",
    "\n",
    "    if pred == 1:\n",
    "        update.message.reply_text(\"üö® –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –¥—Ä–∞–∫–∞!\")\n",
    "    else:\n",
    "        update.message.reply_text(\"‚úÖ –í–∏–¥–µ–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ.\")\n",
    "\n",
    "# === –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞ ===\n",
    "def main():\n",
    "    TOKEN = \"7573920965:AAFVfXMiikWQmfKchv7CI20yVvFzQlBu4cQ\"\n",
    "    updater = Updater(TOKEN, use_context=True)\n",
    "    dp = updater.dispatcher\n",
    "\n",
    "    dp.add_handler(MessageHandler(Filters.video | Filters.document.video, handle_video))\n",
    "\n",
    "    print(\"–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω...\")\n",
    "    updater.start_polling()\n",
    "    updater.idle()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
