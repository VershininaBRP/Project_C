{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e098120-f86c-4549-bd0e-bb7884e153e8",
   "metadata": {},
   "source": [
    "# **–°–æ–∑–¥–∞–Ω–∏–µ —á–∞—Ç-–±–æ—Ç–∞**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47150c6-ecb6-4145-8398-6b1e565d702f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from telegram.ext import Updater, MessageHandler, Filters\n",
    "from telegram import Update\n",
    "from telegram.ext import CallbackContext\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaa135e-7a13-47e3-8cfc-50a01b59e209",
   "metadata": {},
   "source": [
    "**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fbf0df-2adf-4ca3-927d-28bd0a1b383d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b38025-5d51-4c3d-abb3-347f7e92b1a9",
   "metadata": {},
   "source": [
    "**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b3f062-8f38-44dd-8c6c-297dd5b199e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simple3DCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv3d(3, 32, kernel_size=(3,3,3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d((1,2,2)),\n",
    "\n",
    "            nn.Conv3d(32, 64, kernel_size=(3,3,3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d((2,2,2)),\n",
    "\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 8 * 28 * 28, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # (B, T, C, H, W) -> (B, C, T, H, W)\n",
    "        x = x.permute(0, 2, 1, 3, 4)\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7226e1b-cd2d-4608-8673-c8c8631c90a5",
   "metadata": {},
   "source": [
    "**–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d66508a-11be-4954-9dcc-b03731943df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Simple3DCNN()\n",
    "model.load_state_dict(torch.load(\"violence_detector.pth\", map_location=device))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4f8f97-2b0e-4e3b-b521-f9376d027f53",
   "metadata": {},
   "source": [
    "**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1378c8e8-d619-47fb-be73-d9f2c9086973",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_size = (112, 112)\n",
    "frames_per_video = 16\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(frame_size),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cad192e-d1a0-4a2a-b38b-fdc9fd3ff10d",
   "metadata": {},
   "source": [
    "**–§—É–Ω–∫—Ü–∏—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–∞–¥—Ä–æ–≤**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdad2e9-bd13-4956-87fb-240f2acb3eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(video_path, num_frames=16):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_indices = torch.linspace(0, total_frames - 1, num_frames).long()\n",
    "    frames = []\n",
    "    for i in range(total_frames):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if i in frame_indices:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame_tensor = transform(frame)\n",
    "            frames.append(frame_tensor)\n",
    "    cap.release()\n",
    "    if len(frames) < num_frames:\n",
    "        for _ in range(num_frames - len(frames)):\n",
    "            frames.append(frames[-1])\n",
    "    return torch.stack(frames)  # (T, C, H, W)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c32823-cafe-4714-ada6-e068efa142fc",
   "metadata": {},
   "source": [
    "**–§—É–Ω–∫—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1b3cf6-a7b3-4ad7-8f4b-306ecc1902dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_violence(video_path, model, device):\n",
    "    frames_tensor = extract_frames(video_path, frames_per_video)\n",
    "    frames_tensor = frames_tensor.unsqueeze(0).to(device)  # (1, T, C, H, W)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(frames_tensor)\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        pred = torch.argmax(probs, dim=1).item()\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195a6d41-d206-43e3-b3ae-cb77f3087cc1",
   "metadata": {},
   "source": [
    "**–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6344a4c7-e94b-4a26-be40-862e33171121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_video(update: Update, context: CallbackContext):\n",
    "    video = update.message.video or update.message.document\n",
    "    if video is None:\n",
    "        update.message.reply_text(\"–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –≤–∏–¥–µ–æ—Ñ–∞–π–ª.\")\n",
    "        return\n",
    "    \n",
    "    file = video.get_file()\n",
    "    file_path = f\"{video.file_unique_id}.mp4\"\n",
    "    file.download(file_path)\n",
    "\n",
    "    update.message.reply_text(\"–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –≤–∏–¥–µ–æ, –ø–æ–¥–æ–∂–¥–∏—Ç–µ...\")\n",
    "\n",
    "    pred = predict_violence(file_path, model, device)\n",
    "    os.remove(file_path)\n",
    "\n",
    "    if pred == 1:\n",
    "        update.message.reply_text(\"üö® –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –¥—Ä–∞–∫–∞!\")\n",
    "    else:\n",
    "        update.message.reply_text(\"‚úÖ –í–∏–¥–µ–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0771b3d1-ca91-4b61-927f-6ba9947d14d1",
   "metadata": {},
   "source": [
    "# **–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a11d1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    TOKEN = \"7573920965:AAFVfXMiikWQmfKchv7CI20yVvFzQlBu4cQ\"\n",
    "    updater = Updater(TOKEN, use_context=True)\n",
    "    dp = updater.dispatcher\n",
    "\n",
    "    dp.add_handler(MessageHandler(Filters.video | Filters.document.video, handle_video))\n",
    "\n",
    "    print(\"–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω...\")\n",
    "    updater.start_polling()\n",
    "    updater.idle()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
